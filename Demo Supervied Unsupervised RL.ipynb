{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530783e2-947c-4686-8b04-4cb15640c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 1745615127.45857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data (square footage, bedroom, neighborhood a encoded values)\n",
    "X = [[2000, 3, 1], [1500, 2, 2], [1800, 3, 3], [1200, 2, 1]]\n",
    "y = [500000, 350000, 450000, 300000]\n",
    "\n",
    "# Split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24721aad-7840-4eae-90ee-44d1ad9019fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: [[3.5e+00 7.5e+02 1.5e+00]\n",
      " [9.0e+00 4.0e+03 4.0e+00]]\n",
      "Labels: [0 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Sample customer data (number of purchases, total spending, product categories)\n",
    "X = np.array([[5, 1000, 2], [10, 5000, 5], [2, 500, 1], [8, 3000, 3]])\n",
    "\n",
    "# Create and fit the KMeans model\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "\n",
    "# Print the cluster centers and labels\n",
    "print(f\"Cluster Centers: {kmeans.cluster_centers_}\")\n",
    "print(f\"Labels: {kmeans.labels_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1402a3b-1495-4713-b65a-7972c3eb20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize Q-table ith zeros for all tate-action pairs\n",
    "Q_table = np.zeros((9,9)) # 9 possible states (board positions) and 9 possible action\n",
    "\n",
    "#Learning parameters\n",
    "alpha = 0.1 # Learning rate\n",
    "gamma = 0.9 # Dicount factor\n",
    "epsilon = 0.1 # Eploration rate\n",
    "\n",
    "# Sample function to select action using epsilon-greedy policy\n",
    "def epsilon_greedy_action(state, Q_table, epsilon):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return np.random.randint(0, 9) # Random action (eplore)\n",
    "    else:\n",
    "        return np.argmax(Q_table[state]) # Bet action (exploit)\n",
    "\n",
    "# Update Q-values after each game (simplified example)\n",
    "def update_q_table(state, action, reward, next_state, Q_table):\n",
    "    Q_table[state, action] = Q_table[state, action] + alpha * (reward + gamma * np.max(Q_table[next_state]) - \n",
    "        Q_table[state, action])\n",
    "\n",
    "# Example simulation of a game here the agent learns\n",
    "for episode in range(1000):\n",
    "    state = np.random.randint(0, 9) # Random initial state\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = epsilon_greedy_action(state, Q_table, epsilon)\n",
    "        next_state = np.random.randint(0, 9) # Simulate net state\n",
    "        reward = 1 if next_state == 'win' else -1 if next_state == 'loss' else 0 # Simulate rewards\n",
    "        update_q_table(state, action, reward, next_state, Q_table)\n",
    "        state = next_state\n",
    "        if reward != 0:\n",
    "            done = True # End the game if win/loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c0b13-fd81-4d27-b8fe-99941a8195c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
