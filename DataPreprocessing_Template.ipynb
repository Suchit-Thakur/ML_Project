{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea4e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1. Prerequisites - Key Python libraries for data cleaning and preprocessing: pandas, Numpy, Scikit-learn, Missingno\n",
    "# Part 2. Create the data cleaning and preprocessing script\n",
    "# Step 1: Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import missingno as msno  # Optional: for visualizing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataset\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv('your_dataset.csv')  # Replace 'your_dataset.csv' with your actual file path\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing values\n",
    "# Visualize missing data (optional)\n",
    "msno.matrix(df)\n",
    "msno.heatmap(df)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Or, fill missing values with the mean\n",
    "df_filled = df.fillna(df.mean())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3322cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle outliers\n",
    "# Identify outliers using Z-score\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df_cleaned))\n",
    "df_no_outliers = df_cleaned[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Or cap outliers at a threshold\n",
    "upper_limit = df_cleaned['column_name'].quantile(0.95)\n",
    "df_cleaned['column_name'] = np.where(df_cleaned['column_name'] > upper_limit, upper_limit, df_cleaned['column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc21b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Scale and normalize data\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_cleaned), columns=df_cleaned.columns)\n",
    "\n",
    "# Z-score Standardization\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df_cleaned), columns=df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99584442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode categorical variables\n",
    "# One-hot encoding for categorical variables\n",
    "df_encoded = pd.get_dummies(df_scaled, columns=['categorical_column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a440d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save the cleaned and preprocessed data\n",
    "# Save the cleaned and preprocessed DataFrame to a new CSV file  \n",
    "df_encoded.to_csv('cleaned_preprocessed_data.csv', index=False)\n",
    "\n",
    "print('Data cleaning and preprocessing complete. File saved as cleaned_preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3. Automate the workflow\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    return df.fillna(df.mean())\n",
    "\n",
    "def remove_outliers(df):\n",
    "    z_scores = np.abs(stats.zscore(df))\n",
    "    return df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "def encode_categorical(df, categorical_columns):\n",
    "    return pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "def save_data(df, output_filepath):\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "\n",
    "# Example usage:\n",
    "df = load_data('your_dataset.csv')\n",
    "df = handle_missing_values(df)\n",
    "df = remove_outliers(df)\n",
    "df = scale_data(df)\n",
    "df = encode_categorical(df, ['categorical_column_name'])\n",
    "save_data(df, 'cleaned_preprocessed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
